import numpy as np

def GradientDescent(x, y):
    rate = 0.001
    [m, n] = np.shape(x)
    x0 = np.ones((m, 1))
    x = np.hstack((x0, x))
    theta = np.random.normal(size=(n+1, 1))
    count = 0
    J = np.power(h(x, theta)-y, 2).sum()
    while count < 10000:
        theta = theta - rate * np.dot(np.transpose(x), h(x, theta)-y)
        J = np.power(h(x, theta) - y, 2).sum()
        if J < 0.001:
            break
        else:
            count = count + 1
    return theta


#这里用的是线性回归，可根据实际情况修改
def h(x, theta):
    h = np.dot(x, theta)
    return h

x = np.array([[1, 2], [2, 1], [2, 3], [3, 5], [1, 3], [4, 2], [7, 3], [4, 5], [11, 3], [8, 7]])
y = np.array([[7], [8], [10], [14], [8], [13], [20], [16], [28], [26]])
#y = 3 + 2 * x1 + x2
theta = RandomGradientDescent(x, y)
#GradientDescent(x, y)
print(theta)

#总结：一开始数据怎么都不对，后来发现是步长设置的太大，以至于错过了最佳点，而且迭代的次数如果太少，也是和实际相差很多。
